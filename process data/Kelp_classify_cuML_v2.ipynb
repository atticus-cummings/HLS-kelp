{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cudf\n",
    "import cuml\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "from cuml.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "from cuml.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = True\n",
    "rf_file = 'cu_rf10'\n",
    "reclassify = True #Reclassify previously classified images\n",
    "show_image = True\n",
    "num_classify = 20\n",
    "#classified_path = r'/mnt/c/users/attic/hls_kelp/imagery/rf_classified_S30'\n",
    "#unclassified_path = r'/mnt/c/users/attic/hls_kelp/imagery/rf_prepped_v3'\n",
    "#unclassified_files = os.listdir(unclassified_path)\n",
    "rf_path = r'/mnt/c/Users/attic/HLS Kelp Detection/random_forest'\n",
    "training_path = r'/mnt/c/Users/attic/HLS Kelp Detection/random_forest/training_data/classified'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 14:33:46,070 - INFO - Retraining model...\n",
      "2024-09-28 14:33:46,074 - INFO - Processing file: HLS.L30.T10UCU.2017225T190739.v2.0_classified.tif\n",
      "2024-09-28 14:33:48,915 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:33:48,916 - INFO - Processed file HLS.L30.T10UCU.2017225T190739.v2.0_classified.tif successfully.\n",
      "2024-09-28 14:33:48,917 - INFO - Processing file: HLS.L30.T10UCU.2017257T190743.v2.0_classified.tif\n",
      "2024-09-28 14:33:51,342 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:33:51,343 - INFO - Processed file HLS.L30.T10UCU.2017257T190743.v2.0_classified.tif successfully.\n",
      "2024-09-28 14:33:51,344 - INFO - Processing file: HLS.L30.T11SKU.2017135T183333.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:33:52,966 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:33:52,966 - INFO - Processed file HLS.L30.T11SKU.2017135T183333.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:33:52,967 - INFO - Processing file: HLS.L30.T11SKU.2017327T183418.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:33:54,476 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:33:54,477 - INFO - Processed file HLS.L30.T11SKU.2017327T183418.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:33:54,478 - INFO - Processing file: HLS.L30.T11SKU.2018042T183356.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:33:56,040 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:33:56,040 - INFO - Processed file HLS.L30.T11SKU.2018042T183356.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:33:56,041 - INFO - Processing file: HLS.L30.T11SKU.2018106T183324.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:33:57,866 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:33:57,866 - INFO - Processed file HLS.L30.T11SKU.2018106T183324.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:33:57,867 - INFO - Processing file: HLS.L30.T11SKU.2018362T183359.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:33:59,472 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:33:59,473 - INFO - Processed file HLS.L30.T11SKU.2018362T183359.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:33:59,473 - INFO - Processing file: HLS.L30.T11SKU.2022133T183402.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:34:01,176 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:34:01,176 - INFO - Processed file HLS.L30.T11SKU.2022133T183402.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:34:01,177 - INFO - Processing file: HLS.L30.T11SKU.2022341T183439.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:34:02,972 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:34:02,972 - INFO - Processed file HLS.L30.T11SKU.2022341T183439.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:34:02,973 - INFO - Processing file: HLS.S30.T11SKU.2017277T184221.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:34:04,777 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:34:04,777 - INFO - Processed file HLS.S30.T11SKU.2017277T184221.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:34:04,778 - INFO - Processing file: HLS.S30.T11SKU.2018012T184731.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:34:07,341 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:34:07,342 - INFO - Processed file HLS.S30.T11SKU.2018012T184731.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:34:07,343 - INFO - Processing file: HLS.S30.T11SKU.2018022T185421.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:34:10,059 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:34:10,060 - INFO - Processed file HLS.S30.T11SKU.2018022T185421.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:34:10,061 - INFO - Processing file: HLS.S30.T11SKU.2018042T184511.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:34:13,249 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:34:13,250 - INFO - Processed file HLS.S30.T11SKU.2018042T184511.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:34:13,252 - INFO - Processing file: HLS.S30.T11SKU.2018052T184401.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:34:15,428 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:34:15,429 - INFO - Processed file HLS.S30.T11SKU.2018052T184401.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:34:15,430 - INFO - Processing file: HLS.S30.T11SKU.2018087T183949.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:34:17,666 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:34:17,667 - INFO - Processed file HLS.S30.T11SKU.2018087T183949.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:34:17,667 - INFO - Processing file: HLS.S30.T11SKU.2018342T184741.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:34:20,416 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:34:20,417 - INFO - Processed file HLS.S30.T11SKU.2018342T184741.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:34:20,418 - INFO - Processing file: HLS.S30.T11SKU.2019077T184101.v2.0_kelp_classified.tif\n",
      "2024-09-28 14:34:22,658 - INFO - Read image shape: (7, 3660, 3660)\n",
      "2024-09-28 14:34:22,660 - INFO - Processed file HLS.S30.T11SKU.2019077T184101.v2.0_kelp_classified.tif successfully.\n",
      "2024-09-28 14:34:22,660 - INFO - Combining training data...\n",
      "2024-09-28 14:34:23,022 - INFO - Combined training data shape: (227725200, 7)\n",
      "2024-09-28 14:34:24,272 - INFO - Creating cuDF DataFrame...\n",
      "2024-09-28 14:34:25,827 - INFO - Splitting data into train and test sets...\n",
      "2024-09-28 14:34:27,676 - INFO - Setting Random Forest parameters...\n",
      "2024-09-28 14:34:27,677 - INFO - Initializing Random Forest classifier...\n",
      "2024-09-28 14:34:27,677 - INFO - Fitting model...\n",
      "2024-09-28 14:41:00,823 - INFO - Predicting test data...\n",
      "2024-09-28 14:41:04,500 - INFO - Accuracy: 0.9680642485618591\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "if retrain:\n",
    "    logging.info(\"Retraining model...\")\n",
    "    training_files = os.listdir(training_path)\n",
    "    filtered_files = [file for file in training_files if not file.endswith('.xml')]\n",
    "    training_data = []\n",
    "\n",
    "    for file in filtered_files:\n",
    "        try:\n",
    "            logging.info(f\"Processing file: {file}\")\n",
    "            # file_data = file.split('.')\n",
    "            # sensor = file_data[1]\n",
    "            # if sensor == 'L30':\n",
    "            #     logging.info(f\"Skipping file: {file} due to sensor type\")\n",
    "            #     continue\n",
    "\n",
    "            with rasterio.open(os.path.join(training_path, file)) as src:\n",
    "                training_img = src.read()\n",
    "            logging.info(f\"Read image shape: {training_img.shape}\")\n",
    "\n",
    "            file_data = training_img.reshape(training_img.shape[0], -1)\n",
    "\n",
    "            training_data.append(file_data)\n",
    "            logging.info(f\"Processed file {file} successfully.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing file {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Combining training data...\")\n",
    "        combined_training_data = np.hstack(training_data).T\n",
    "        del training_data, training_img\n",
    "        logging.info(f\"Combined training data shape: {combined_training_data.shape}\")   \n",
    "        combined_training_data = combined_training_data[combined_training_data[:, 6] != 3]\n",
    "        logging.info(\"Creating cuDF DataFrame...\")\n",
    "        df = cudf.DataFrame(combined_training_data)\n",
    "        X = df.iloc[:, :-1].astype('float32')\n",
    "        y = df.iloc[:, -1].astype('float32')\n",
    "        del df\n",
    "        logging.info(\"Splitting data into train and test sets...\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.95, random_state=42)\n",
    "        \n",
    "        logging.info(\"Setting Random Forest parameters...\")\n",
    "        cu_rf_params = {\n",
    "            'n_estimators': 100,  # Increase number of trees\n",
    "            'max_depth': 150,     # Increase maximum depth\n",
    "            'n_bins': 40,         # Increase number of bins\n",
    "            'n_streams': 8     # Adjust parallel streams based on GPU capability\n",
    "        }\n",
    "\n",
    "        logging.info(\"Initializing Random Forest classifier...\")\n",
    "        cu_rf = cuRF(**cu_rf_params)\n",
    "        \n",
    "        logging.info(\"Fitting model...\")\n",
    "        cu_rf.fit(X_train, y_train)\n",
    "        \n",
    "        logging.info(\"Predicting test data...\")\n",
    "        y_pred = cu_rf.predict(X_test)\n",
    "        \n",
    "        accuracy = cuml.metrics.accuracy_score(y_test, y_pred)\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during training: {e}\")\n",
    "\n",
    "else:\n",
    "    logging.info(\"Retrain set to False\")\n",
    "\n",
    "if retrain: \n",
    "    if not os.path.isdir(rf_path):\n",
    "        os.mkdir(rf_path)\n",
    "    with open(os.path.join(rf_path, rf_file), 'wb') as f:\n",
    "        pickle.dump(cu_rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cu_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain: \n",
    "    if not os.path.isdir(rf_path):\n",
    "        os.mkdir(rf_path)\n",
    "    with open(os.path.join(rf_path, rf_file), 'wb') as f:\n",
    "        pickle.dump(cu_rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unclassified_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(rf_path,rf_file), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m         cu_rf \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43munclassified_files\u001b[49m[\u001b[38;5;241m6\u001b[39m:\u001b[38;5;241m50\u001b[39m]):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(i \u001b[38;5;241m>\u001b[39m num_classify):\n\u001b[1;32m      7\u001b[0m          \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unclassified_files' is not defined"
     ]
    }
   ],
   "source": [
    "if not retrain:\n",
    "    with open(os.path.join(rf_path,rf_file), 'rb') as f:\n",
    "        cu_rf = pickle.load(f)\n",
    "\n",
    "for i, file in enumerate(unclassified_files[6:50]):\n",
    "    if(i > num_classify):\n",
    "         break\n",
    "    file_data = file.split('.')\n",
    "    sensor = file_data[1]\n",
    "    # if(sensor != 'L30'):\n",
    "    #      continue\n",
    "    file_name = file.split('_')\n",
    "    if not reclassify and os.path.isfile(os.path.join(classified_path, f'{file_name[0]}_kelp_classified.tif')):\n",
    "        print(f\"{file} already classified\")\n",
    "        continue\n",
    "    file_img =[]\n",
    "    with rasterio.open(os.path.join(unclassified_path,file)) as src:\n",
    "        file_img = src.read(indexes=[1, 2, 3, 4, 5, 6])\n",
    "        img = np.stack(file_img, axis=0)\n",
    "        n_bands, height, width = img.shape\n",
    "        img_2D = img.reshape(img.shape[0], -1).T #classifier takes 2D array of band values for each pixel \n",
    "    #normalized_img_bands = np.column_stack((img_2D, cloud_mask_2D))\n",
    " ##========== Normalize multi-spectral data ==========##\n",
    "        img_sum = img_2D.sum(axis=1)\n",
    "        epsilon = 1e-10  \n",
    "        img_2D_nor = np.divide(img_2D, img_sum[:, None] + epsilon, where=(img_sum[:, None] != 0))\n",
    "        img_2D_nor = (img_2D_nor * 255).astype(np.uint8)\n",
    "        #img_normalized = img_2D_normalized.reshape((height, width))\n",
    "            # img_sum_nonzero = np.where(img_sum == 0, 1, img_sum)\n",
    "            # img_2D_normalized = img_2D / img_sum_nonzero[:, None] #divide value by sum of pixel band values\n",
    "            # print(img_2D_normalized.shape)\n",
    "            # img_2D_normalized = (img_2D_normalized * 255)\n",
    "            # img_2D_normalized = img_2D_normalized.astype(np.uint8)\n",
    "\n",
    "        #img_data= file_img.reshape(file_img.shape[0], -1).T\n",
    "        img_data = cudf.DataFrame(img_2D_nor)\n",
    "        img_data = img_data.astype(np.float32)\n",
    "        kelp_pred = cu_rf.predict(img_data)\n",
    "        kelp_img = kelp_pred.values_host.reshape(width,height)\n",
    "        if show_image:\n",
    "            print(file)\n",
    "            plt.figure(figsize=(25, 25)) \n",
    "            plt.subplot(2, 1, 1)  \n",
    "            plt.imshow(kelp_img)#[2700:3400, 600:2000])\n",
    "            plt.title(file)\n",
    "            r_nor = img_2D_nor[:,2].reshape((height, width))\n",
    "            g_nor = img_2D_nor[:,1].reshape((height, width))\n",
    "            b_nor = img_2D_nor[:,0].reshape((height, width))\n",
    "            rgb_nor = np.stack([r_nor,g_nor,b_nor], axis=-1)  \n",
    "            rgb_cropped = rgb_nor#[2700:3400, 600:2000]\n",
    "            plt.subplot(2, 1, 2) \n",
    "            plt.imshow(rgb_cropped)\n",
    "            plt.title(\"RGB Cropped Image\")\n",
    "            #plt.colorbar()\n",
    "            plt.show()\n",
    "        data_type = rasterio.int16\n",
    "        profile = {\n",
    "            'driver': 'GTiff',\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'count': 5,  # one band  B02, B03, B04, and B05, classified (Blue, Green, Red, and NIR).\n",
    "            'dtype': data_type,  # assuming binary mask, adjust dtype if needed\n",
    "            'crs': src.crs,\n",
    "            'transform': src.transform,\n",
    "            'nodata': 0  # assuming no data is 0\n",
    "        }\n",
    "        # Write the land mask array to GeoTIFF\n",
    "        if not os.path.isdir(classified_path):\n",
    "            os.mkdir(classified_path)\n",
    "        with rasterio.open(os.path.join(classified_path, f'{file_name[0]}_kelp_classified.tif'), 'w', **profile) as dst:\n",
    "                dst.write(file_img[0].astype(data_type), 1)\n",
    "                dst.write(file_img[1].astype(data_type), 2)\n",
    "                dst.write(file_img[2].astype(data_type), 3)\n",
    "                dst.write(file_img[3].astype(data_type), 4)\n",
    "                dst.write(kelp_img.astype(rasterio.uint8), 5)\n",
    "        print(f'{i+1} / {len(unclassified_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cu_rf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
